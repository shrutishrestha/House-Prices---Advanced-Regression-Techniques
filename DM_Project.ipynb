{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o41_K1oWi6D2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 Read data"
      ],
      "metadata": {
        "id": "0ae07aWCj0Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = \"train.csv\"\n",
        "test_csv = \"test.csv\"\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)"
      ],
      "metadata": {
        "id": "P42ZnM4Ai9xt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Seperating numerical and categorical values"
      ],
      "metadata": {
        "id": "KG4pMqa5jzEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_feature_description = train_df.select_dtypes(exclude = ['object']).describe().round(decimals=2).transpose()\n",
        "categorical_feature_description = train_df.select_dtypes(include = ['object']).describe().transpose()"
      ],
      "metadata": {
        "id": "7eklpOUDmwIw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the columns and their null values"
      ],
      "metadata": {
        "id": "w1FXA3V6j1ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "eYKshkNCjJZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d300b0dc-3c31-4249-f146-d5c3ed4a1cb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoolQC         1453\n",
              "MiscFeature    1406\n",
              "Alley          1369\n",
              "Fence          1179\n",
              "FireplaceQu     690\n",
              "               ... \n",
              "ExterQual         0\n",
              "Exterior2nd       0\n",
              "Exterior1st       0\n",
              "RoofMatl          0\n",
              "SalePrice         0\n",
              "Length: 81, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting Id, PoolQC, MiscFeature, Alley, Fence as they have more than 80% missing values"
      ],
      "metadata": {
        "id": "tMax0_Pp1f5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deleting_columns = [\"Id\",\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"]\n",
        "train_df_processed = train_df.drop(deleting_columns, axis=1)\n",
        "numerical_feature = list(set(train_df.select_dtypes(exclude = ['object']).columns) - set(deleting_columns))\n",
        "categorical_feature = list(set(train_df.select_dtypes(include = ['object']).columns) - set(deleting_columns))"
      ],
      "metadata": {
        "id": "zIcWKLAhkGx6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Handling missing values**"
      ],
      "metadata": {
        "id": "6H4CfJfnsFMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 for numerical missing values"
      ],
      "metadata": {
        "id": "yk5syBm_kuJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_numeric = train_df_processed[numerical_feature]\n",
        "numeric_columns = train_df_numeric.columns\n",
        "train_df_numeric.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXSkDLfkmOqV",
        "outputId": "913438d4-0246-4631-bc23-76415cbecdcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "train_array_numeric_processed = imputer.fit_transform(train_df_numeric)\n",
        "train_df_numeric_processed = pd.DataFrame(train_array_numeric_processed, columns = numeric_columns)"
      ],
      "metadata": {
        "id": "OYmOeCWbklO-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_processed[numerical_feature] = train_df_numeric_processed[numerical_feature]"
      ],
      "metadata": {
        "id": "h2IXcKQzExpS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_processed.columns[train_df_processed.isnull().any()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgu0sVbrRWVS",
        "outputId": "b82e51c6-d56c-4a09-9a6d-56d6e436243e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
              "       'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType',\n",
              "       'GarageFinish', 'GarageQual', 'GarageCond'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2. For Categorical missing values"
      ],
      "metadata": {
        "id": "y2GVFvMFr3L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catfeatures_containing_null = ['MasVnrType','BsmtFinType1','BsmtFinType2','GarageQual','GarageType','BsmtExposure','Electrical','BsmtQual','GarageCond','FireplaceQu','GarageFinish','BsmtCond']"
      ],
      "metadata": {
        "id": "I9aiu4zAsSXJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_processed_copy = train_df_processed.copy()"
      ],
      "metadata": {
        "id": "a8ICvctMmJeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_X = train_df_processed_copy.drop(catfeatures_containing_null, axis=1)\n"
      ],
      "metadata": {
        "id": "oYZdEpdCmuJq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data_X = data_X.select_dtypes(exclude = ['object']).columns\n",
        "categorical_data_X = data_X.select_dtypes(include = ['object']).columns"
      ],
      "metadata": {
        "id": "MLlLARLZoJb7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#numericals to scaling\n",
        "num_df = data_X[numerical_data_X]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(num_df)\n",
        "num_df_scaled = scaler.transform(num_df)\n",
        "\n",
        "num_df_scaled = pd.DataFrame(num_df_scaled, columns = num_df.columns)\n",
        "num_df_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyauduha3Sy7",
        "outputId": "870484b8-16e7-40e3-bfa4-2a1acc3ea13f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical encoding\n",
        "#all remove stage\n",
        "\n",
        "cat_df = data_X[categorical_data_X]\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onc = OneHotEncoder()\n",
        "onc.fit(cat_df)\n",
        "\n",
        "cat_df_encoded = onc.transform(cat_df)\n",
        "cat_df_encoded = pd.DataFrame(cat_df_encoded.toarray())\n",
        "cat_df_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLQ19qTr4dZ7",
        "outputId": "b74d6bc6-dde3-4124-fd30-9952c804d9f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 182)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df = pd.concat([num_df_scaled, cat_df_encoded], axis=1)"
      ],
      "metadata": {
        "id": "r5BoSLQd_NAY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "cIfw6i27Hj5g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knc = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "XkXKl6viOLNd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catfeatures_containing_null = ['Electrical','MasVnrType','BsmtFinType1','BsmtFinType2','GarageQual','GarageType','BsmtExposure','BsmtQual','GarageCond','FireplaceQu','GarageFinish','BsmtCond']\n",
        "total_df_copy = total_df.copy()\n",
        "for col in catfeatures_containing_null:\n",
        "\n",
        "  data_Y = train_df_processed[col]\n",
        "  data_X = total_df_copy\n",
        "\n",
        "  knc = KNeighborsClassifier()\n",
        "  train_idx = [index for index, row in pd.DataFrame(data_Y).iterrows() if row.isnull().any()]\n",
        "\n",
        "  X_val = data_X.iloc[train_idx]\n",
        "  y_val = data_Y.iloc[train_idx]\n",
        "\n",
        "  val_df = data_X.index.isin(train_idx)\n",
        "\n",
        "  X_train = data_X[~val_df]\n",
        "  y_train = data_Y[~val_df]\n",
        "\n",
        "  knc.fit(X_train, y_train)\n",
        "  y_pred = knc.predict(X_val)\n",
        "\n",
        "  new = np.array(y_train.tolist() + y_pred.tolist())\n",
        "  new_arr = new.reshape(-1, 1)\n",
        "\n",
        "  #numericals to scaling\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  onc = OneHotEncoder()\n",
        "  onc.fit(new_arr)\n",
        "  new_encoded = onc.transform(new_arr)\n",
        "\n",
        "  new_encoded_df = pd.DataFrame(new_encoded.toarray())\n",
        "\n",
        "  new_encoded_df.columns = [col+str(i) for i in range(0,new_encoded_df.shape[1])] \n",
        "\n",
        "  total_df_copy = pd.concat([total_df_copy, new_encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "A9xEM6-wKU4k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df_copy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uls_pppJ8W5_",
        "outputId": "2b4fd4d3-7ee5-4fa9-aa42-531f45158b2c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 276)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming target\n"
      ],
      "metadata": {
        "id": "__r3Zirw_d8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import absolute\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "\n",
        "X,y = total_df_copy.drop(['SalePrice'], axis=1), train_df_processed['SalePrice']\n",
        "pipeline = Pipeline(steps=[('normalize', MinMaxScaler()), ('model', HuberRegressor())])\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer = MinMaxScaler())\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "scores = cross_validate(model, X,y, scoring = ('r2', 'neg_mean_squared_error'), cv = cv, n_jobs=1)\n",
        "\n",
        "r2_mean = np.mean(scores['test_r2'])\n",
        "neg_mean_squared_error_mean = np.mean(absolute(scores['test_neg_mean_squared_error']))\n",
        "\n",
        "print(neg_mean_squared_error_mean)\n",
        "print(r2_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL6kSpgg_dRS",
        "outputId": "4a8ae091-bf5c-45e6-a9cc-f616e8d70701"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1028797211.4538021\n",
            "0.8253812671415945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = total_df_copy.drop(['SalePrice'], axis=1), train_df_processed['SalePrice']\n",
        "pipeline = Pipeline(steps=[('normalize', MinMaxScaler()), ('model', LinearRegression())])\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer = MinMaxScaler())\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "scores = cross_validate(model, X,y, scoring = ('r2', 'neg_mean_squared_error'), cv = cv, n_jobs=1)\n",
        "\n",
        "\n",
        "r2_mean = np.mean(scores['test_r2'])\n",
        "neg_mean_squared_error_mean = np.mean(absolute(scores['test_neg_mean_squared_error']))\n",
        "\n",
        "print(neg_mean_squared_error_mean)\n",
        "print(r2_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ts6JqQI8jXC",
        "outputId": "b6f241c1-25b3-4951-8618-bb7cbb5089ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0880349242170358e+29\n",
            "-1.7890261442630791e+19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "X,y = total_df_copy.drop(['SalePrice'], axis=1), train_df_processed['SalePrice']\n",
        "pipeline = Pipeline(steps=[('normalize', MinMaxScaler()), ('model', Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42))])\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer = MinMaxScaler())\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "scores = cross_validate(model, X,y, scoring = ('r2', 'neg_mean_squared_error'), cv = cv, n_jobs=1)\n",
        "\n",
        "\n",
        "r2_mean = np.mean(scores['test_r2'])\n",
        "neg_mean_squared_error_mean = np.mean(absolute(scores['test_neg_mean_squared_error']))\n",
        "\n",
        "print(neg_mean_squared_error_mean)\n",
        "print(r2_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXdUKha0_n-1",
        "outputId": "0c74c6dd-1091-47f9-acfa-8c3974e67161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1489916818.3822799\n",
            "0.7620748473034932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X,y = total_df_copy.drop(['SalePrice'], axis=1), train_df_processed['SalePrice']\n",
        "pipeline = Pipeline(steps=[('normalize', MinMaxScaler()), ('model', Lasso(alpha=0.1, \n",
        "              precompute=True, \n",
        "#               warm_start=True, \n",
        "              positive=True, \n",
        "              selection='random',\n",
        "              random_state=42))])\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer = MinMaxScaler())\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "scores = cross_validate(model, X,y, scoring = ('r2', 'neg_mean_squared_error'), cv = cv, n_jobs=1)\n",
        "# scores = absolute(scores)\n",
        "# s_mean = np.mean(scores)\n",
        "# print(s_mean)\n",
        "\n",
        "\n",
        "r2_mean = np.mean(scores['test_r2'])\n",
        "neg_mean_squared_error_mean = np.mean(absolute(scores['test_neg_mean_squared_error']))\n",
        "\n",
        "print(neg_mean_squared_error_mean)\n",
        "print(r2_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVJkr-LOACgj",
        "outputId": "079dd372-71b5-48fe-f5cf-746d0b174f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6311984871.911216\n",
            "-0.004258855785411808\n"
          ]
        }
      ]
    }
  ]
}